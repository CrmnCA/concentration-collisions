{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.special import gamma, loggamma, factorial\n",
    "import scipy.stats\n",
    "from scipy.interpolate import interp1d\n",
    "from matplotlib.ticker import AutoMinorLocator \n",
    "from matplotlib import rc, font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import colors as mcolors\n",
    "from matplotlib import legend_handler\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size\n",
    "import collections\n",
    "import shapefile\n",
    "import matplotlib\n",
    "from OSGridConverter import latlong2grid\n",
    "import shapely.geometry\n",
    "import shapely.ops \n",
    "from descartes.patch import PolygonPatch\n",
    "from geopy.geocoders import Nominatim\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import io\n",
    "import pysal\n",
    "from pysal.lib import weights\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts(gdf_collisions, gdf_geography):\n",
    "    \n",
    "    gdf_geography['index'] = [i for i in range(len(gdf_geography))]\n",
    "    #Add geography to each event, aggregate events with same geography, add number of counts to each geography\n",
    "    gdf_collisions['Counts'] = ['Counts' for i in range(len(gdf_collisions))]\n",
    "    gdf_join = gpd.sjoin(gdf_geography, gdf_collisions)\n",
    "    dfpivot = pd.pivot_table(gdf_join, index='index', columns='Counts', aggfunc={'Counts':len})\n",
    "    dfpivot.columns = dfpivot.columns.droplevel()\n",
    "    gdf_counts = gdf_geography.merge(dfpivot, how='left', on='index')\n",
    "    gdf_counts['Counts'] = gdf_counts['Counts'].fillna(0)\n",
    "    gdf_counts['Events/km_road'] = np.zeros(len(gdf_counts))\n",
    "    for j in range(len(gdf_counts)):\n",
    "        if float(gdf_counts.loc[j, 'length_roa']) != 0:\n",
    "            gdf_counts.loc[j, 'Events/km_road'] = gdf_counts.loc[j, 'Counts']/float(gdf_counts.loc[j, 'length_roa'])*1e3\n",
    "    return gdf_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_lag(gdf, w_neighbours):\n",
    "\n",
    "    WY = []\n",
    "    for i in range(len(gdf)):\n",
    "        wy = 0\n",
    "        index_neighbours = w_neighbours[i]\n",
    "        for j in index_neighbours:\n",
    "            wy += gdf.loc[j, 'Events/km_road']\n",
    "        wy /= len(index_neighbours)\n",
    "        WY.append(wy)\n",
    "    gdf['WY'] = WY\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cumulatives(gdf):    \n",
    "    \n",
    "    # Find cumulative distribution for WY\n",
    "    gdf = gdf.sort_values(by='WY').reset_index(drop=True)\n",
    "    gdf['F_WY'] = np.arange(len(gdf))/len(gdf)\n",
    "    \n",
    "    # Find cumulative distribution for Y\n",
    "    gdf = gdf.sort_values(by='Events/km_road').reset_index(drop=True)\n",
    "    gdf['F_Y'] = np.arange(len(gdf))/len(gdf)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_gamma(gdf):\n",
    "    \n",
    "    Y = gdf['Events/km_road']\n",
    "    F_Y = list(gdf['F_Y'])\n",
    "    F_WY = list(gdf['F_WY'])\n",
    "    cov_Y = 0\n",
    "    cov_WY = 0\n",
    "    mean_Y = np.mean(Y)\n",
    "    mean_F_Y = np.mean(F_Y)\n",
    "    mean_F_WY = np.mean(F_WY)\n",
    "    index_non_zero = 0\n",
    "    while Y[index_non_zero]==0:\n",
    "        index_non_zero+=1\n",
    "    for i in range(len(Y)):\n",
    "        cov_Y += (Y[i]-mean_Y)*(F_Y[i]-mean_F_Y)\n",
    "        cov_WY += (Y[i]-mean_Y)*(F_WY[i]-mean_F_WY)\n",
    "    cov_Y = cov_Y/len(Y)\n",
    "    cov_WY = cov_WY/len(Y)\n",
    "    # Gini\n",
    "    gini = 2*cov_Y/mean_Y\n",
    "    # spatial Gini\n",
    "    gini_s = 2*cov_WY/mean_Y\n",
    "    # Gini correlation\n",
    "    gamma = gini_s/gini\n",
    "    return gini, gini_s, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moransI(gdf, w_neighbours):\n",
    "    \n",
    "    Y = gdf['Events/km_road']\n",
    "    mean_Y = np.mean(Y)\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    W = 0\n",
    "    for i in range(len(Y)):\n",
    "        index_neighbours = w_neighbours[i]\n",
    "        denominator += (Y[i] - mean_Y)**2\n",
    "        W += len(index_neighbours)\n",
    "        for j in index_neighbours:\n",
    "            numerator += (Y[i]-mean_Y)*(Y[j]-mean_Y)\n",
    "    I = (len(Y)/W)*(numerator/denominator)\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events England in year 2015:  125637\n",
      "Filtered events England in year 2015:  19006\n",
      "Total events England in year 2016:  123348\n",
      "Filtered events England in year 2016:  20840\n",
      "Total events England in year 2017:  118297\n",
      "Filtered events England in year 2017:  21758\n",
      "Total events England in year 2018:  111978\n",
      "Filtered events England in year 2018:  22323\n",
      "Total events England in year 2019:  113222\n",
      "Filtered events England in year 2019:  23586\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/CrmnCA/concentration-collisions/master/'\n",
    "years = [15,16,17,18,19]\n",
    "download = requests.get(url + 'Accidents' + str(years[0]) + '.csv').content\n",
    "df = pd.read_csv(io.StringIO(download.decode('utf-8')), low_memory=False)\n",
    "index_to_drop = []\n",
    "for i in range(len(df)):\n",
    "    if type(df.loc[i,'LSOA_of_Accident_Location']) != str:\n",
    "        index_to_drop.append(i)\n",
    "df = df.drop(index_to_drop).reset_index(drop=True)\n",
    "df = df[df['LSOA_of_Accident_Location'] < 'F'] #Select collisions in England\n",
    "print('Total events England in year 20' + str(years[0]) +': ', len(df))\n",
    "df = df[df['Accident_Severity']<3].reset_index(drop=True) #Select fatal and serious collisions (1:fatal, 2:serious, 3:minor)\n",
    "print('Filtered events England in year 20' + str(years[0]) +': ', len(df))\n",
    "df = df[['Location_Easting_OSGR', 'Location_Northing_OSGR', 'Date', 'Time']]\n",
    "for i in range(1, len(years)):\n",
    "    download = requests.get(url + 'Accidents' + str(years[i]) + '.csv').content\n",
    "    df_year = pd.read_csv(io.StringIO(download.decode('utf-8')), low_memory=False)\n",
    "    index_to_drop = []\n",
    "    for j in range(len(df_year)):\n",
    "        if type(df_year.loc[j,'LSOA_of_Accident_Location']) != str:\n",
    "            index_to_drop.append(j)\n",
    "    df_year = df_year.drop(index_to_drop).reset_index(drop=True)\n",
    "    df_year = df_year[df_year['LSOA_of_Accident_Location'] < 'F'] #Select collisions in England\n",
    "    print('Total events England in year 20' + str(years[i]) +': ', len(df_year))\n",
    "    df_year = df_year[df_year['Accident_Severity']<3].reset_index(drop=True) #Select fatal and serious collisions (1:fatal, 2:serious, 3:minor)\n",
    "    print('Filtered events England in year 20' + str(years[i]) +': ', len(df_year))\n",
    "    df_year = df_year[['Location_Easting_OSGR', 'Location_Northing_OSGR', 'Date', 'Time']]\n",
    "    nan_value = float('NaN')\n",
    "    df_year.replace('', nan_value)\n",
    "    df_year = df_year.dropna().reset_index(drop=True)\n",
    "    df = pd.concat([df, df_year], ignore_index=True)\n",
    "gdf_collisions = gpd.GeoDataFrame(df, crs = 'EPSG:27700', geometry=gpd.points_from_xy(df.Location_Easting_OSGR, df.Location_Northing_OSGR))\n",
    "gdf_collisions = gdf_collisions[['geometry', 'Date', 'Time']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Gini index  Morans I  Gini correlation\n",
      "0     0.596351  0.547753          0.611252\n",
      "1     0.625345  0.227980          0.365338\n",
      "2     0.556988  0.392787          0.553605\n",
      "3     0.612705  0.275978          0.371154\n",
      "4     0.563777  0.341889          0.558914\n",
      "5     0.556300  0.276350          0.391712\n",
      "6     0.565544  0.259343          0.319912\n",
      "7     0.631272  0.325102          0.461504\n",
      "8     0.565721  0.332524          0.489079\n",
      "9     0.669120  0.353768          0.516559\n",
      "10    0.627225  0.467952          0.604073\n",
      "11    0.551557  0.348610          0.570412\n",
      "12    0.607338  0.187227          0.413179\n",
      "13    0.547669  0.255661          0.372395\n",
      "14    0.642275  0.161287          0.317746\n",
      "15    0.665074  0.155498          0.325759\n",
      "16    0.607262  0.108229          0.289423\n",
      "17    0.699899  0.249570          0.456032\n",
      "18    0.569642  0.251412          0.424745\n",
      "19    0.612479  0.218105          0.341946\n",
      "20    0.569052  0.320517          0.543589\n",
      "21    0.588833  0.119748          0.460038\n",
      "22    0.610194  0.421481          0.631269\n",
      "23    0.552346  0.227592          0.362886\n",
      "24    0.589543  0.238390          0.420731\n",
      "25    0.615711  0.167229          0.344022\n",
      "26    0.568975  0.202004          0.368833\n",
      "27    0.610759  0.175813          0.409130\n",
      "28    0.552098  0.199589          0.371107\n",
      "29    0.604323  0.078223          0.228420\n",
      "30    0.625249  0.364564          0.483598\n",
      "31    0.617909  0.231223          0.408075\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/CrmnCA/concentration-collisions/master/Hexagons_cities_with_roadway_length.geojson'\n",
    "gdf_hexagons_cities=gpd.read_file(url, crs='EPSG:27700')\n",
    "ginis, ginis_s, gammas, morans = [], [], [], []\n",
    "for i in range(0,32):\n",
    "    gdf_hexagons_city = gdf_hexagons_cities[gdf_hexagons_cities['city']==i].reset_index(drop=True)\n",
    "    gdf_count = counts(gdf_collisions, gdf_hexagons_city)  \n",
    "    w_neighbours = weights.fuzzy_contiguity(gdf_count, tolerance=0.001, buffering=True)\n",
    "    w_neighbours = {i:list(w_neighbours[i].keys()) for i in range(len(gdf_count))} \n",
    "    moran = moransI(gdf_count, w_neighbours)\n",
    "    morans.append(moran)\n",
    "    gdf_count = spatial_lag(gdf_count, w_neighbours)\n",
    "    gdf_count = find_cumulatives(gdf_count)\n",
    "    gini, gini_s, gamma = gini_gamma(gdf_count)\n",
    "    ginis.append(gini)\n",
    "    ginis_s.append(gini_s)\n",
    "    gammas.append(gamma)   \n",
    "    \n",
    "print(pd.DataFrame({'Gini index':ginis, 'Morans I': morans, 'Gini correlation': gammas}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
